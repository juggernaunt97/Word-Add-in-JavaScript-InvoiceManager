{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 763
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5974,
     "status": "ok",
     "timestamp": 1565235591795,
     "user": {
      "displayName": "Quang Nguyen Hong",
      "photoUrl": "",
      "userId": "11334091556691464686"
     },
     "user_tz": -420
    },
    "id": "veaSBgwFSssP",
    "outputId": "affc1dbf-ac77-4568-bb45-d9b4b011c5c2"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-180de7dc81a5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdatasets\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mfashion_mnist\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcore\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mActivation\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "from keras.datasets import fashion_mnist\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation\n",
    "from keras.optimizers import SGD, Adam \n",
    "from keras.utils import np_utils\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(1671)  # for reproducibility\n",
    "\n",
    "# network and training\n",
    "NB_EPOCH = 2\n",
    "BATCH_SIZE = 128\n",
    "VERBOSE = 1\n",
    "NB_CLASSES = 10   # number of outputs = number of digits\n",
    "OPTIMIZER = SGD() # SGD optimizer\n",
    "N_HIDDEN = 128\n",
    "VALIDATION_SPLIT = 0.2 # how much TRAIN is reserved for VALIDATION\n",
    "\n",
    "# data: shuffled and split between train and test sets\n",
    "#\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "print(\"X_train: \", X_train.shape)\n",
    "print(\"y_train: \", y_train.shape)\n",
    "print(\"X_test: \", X_test.shape)\n",
    "print(\"y_test: \", y_test.shape)\n",
    "\n",
    "class_names = {i:cn for i, cn in enumerate(['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']) }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(X_test[0], cmap = plt.cm.binary)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-84448d840915>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m10\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mimages\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum_row\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mnum_col\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;31m# plot images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X_test' is not defined"
     ]
    }
   ],
   "source": [
    "num = 10\n",
    "images = X_test[:num]\n",
    "labels = y_test[:num]\n",
    "num_row = 2\n",
    "num_col = 5# plot images\n",
    "fig, axes = plt.subplots(num_row, num_col, figsize=(1.5*num_col,2*num_row))\n",
    "for i in range(num):\n",
    "    ax = axes[i//num_col, i%num_col]\n",
    "    ax.imshow(images[i], cmap = plt.cm.binary)\n",
    "    ax.set_title('Label: {}'.format(labels[i]))\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 train samples\n",
      "10000 test samples\n",
      "Y of 2 samples : \n",
      " [[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "#X_train is 60000 rows of 28x28 values --> reshaped in 60000 x 784\n",
    "RESHAPED = 784\n",
    "#\n",
    "X_train = X_train.reshape(60000, RESHAPED)\n",
    "X_test = X_test.reshape(10000, RESHAPED)\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "\n",
    "# normalize \n",
    "#\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, NB_CLASSES)\n",
    "Y_test = np_utils.to_categorical(y_test, NB_CLASSES)\n",
    "\n",
    "print(\"Y of 2 samples : \\n\", Y_test[:2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_11 (Dense)             (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 1s 19us/step - loss: 1.2432 - acc: 0.6139 - val_loss: 0.9009 - val_acc: 0.7114\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 1s 14us/step - loss: 0.8292 - acc: 0.7360 - val_loss: 0.7594 - val_acc: 0.7552\n",
      "10000/10000 [==============================] - 0s 13us/step\n",
      "\n",
      "Test score: 0.7811874876976013\n",
      "Test accuracy: 0.7407\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(NB_CLASSES, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    #batch_size=BATCH_SIZE, epochs=100,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_12 (Dense)             (None, 10)                7850      \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 10)                0         \n",
      "=================================================================\n",
      "Total params: 7,850\n",
      "Trainable params: 7,850\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 48000 samples, validate on 12000 samples\n",
      "Epoch 1/2\n",
      "48000/48000 [==============================] - 1s 23us/step - loss: 0.7819 - acc: 0.7420 - val_loss: 0.5747 - val_acc: 0.8079\n",
      "Epoch 2/2\n",
      "48000/48000 [==============================] - 1s 15us/step - loss: 0.5338 - acc: 0.8227 - val_loss: 0.5118 - val_acc: 0.8226\n",
      "10000/10000 [==============================] - 0s 12us/step\n",
      "\n",
      "Test score: 0.5387159660816193\n",
      "Test accuracy: 0.8134\n"
     ]
    }
   ],
   "source": [
    "OPTIMIZER = Adam()\n",
    "# 10 outputs\n",
    "# final stage is softmax\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(NB_CLASSES, input_shape=(RESHAPED,)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=OPTIMIZER,\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=BATCH_SIZE, epochs=NB_EPOCH,\n",
    "                    #batch_size=BATCH_SIZE, epochs=100,\n",
    "                    verbose=VERBOSE, validation_split=VALIDATION_SPLIT)\n",
    "score = model.evaluate(X_test, Y_test, verbose=VERBOSE)\n",
    "print(\"\\nTest score:\", score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist_keras.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
